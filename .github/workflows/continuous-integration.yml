name: Salesforce CI/CD Logic

# This workflow can ONLY be called from another repository
on:
  workflow_call:
    inputs:
      target-env:
        description: 'Salesforce Target Environment Alias (e.g., sandbox, prod)'
        required: true
        type: string
      deployment-mode:
        description: 'Deployment Mode (DELTA or FULL)'
        required: true
        type: string
      test-level:
        description: 'Test Level (NoTestRun, RunLocalTests, RunSpecifiedTests)'
        required: false
        type: string
      check-only:
        description: 'Run deployment as check-only (validation)'
        required: true
        type: boolean
      outputdir:
        description: 'Output directory for artifacts'
        required: false
        type: string
        default: 'results'
      change-detection-type:
        description: 'Metadata type for test class detection (e.g., classes, all)'
        required: false
        type: string
        default: 'classes'
      test-class-regex: 
        description: 'Regex for matching test class names'
        required: false
        type: string
        default: '.*Test.*$'
      org-preconfig:
        description: 'Run pre-deployment org configuration data step'
        required: false
        type: boolean
        default: false # Set a default value
      run-code-scanner:
        description: 'Run Salesforce code analyzer'
        required: false
        type: boolean
        default: false # Set a default value
      run-data-import: 
        description: Run data import
        required: false 
        type: boolean 
        default: false
      auto-publish-communities: 
        description: automatically publish all experience cloud communities
        required: false 
        type: boolean 
        default: false
      runjest: 
        description: run lwc test
        required: false 
        type: boolean 
        default: false
jobs:
  salesforce_ci:
    runs-on: ubuntu-latest
    container: brovasi/dxb
    environment: ${{ inputs.target-env }}

    env:
      # Map inputs to environment variables used in the script
      TARGET_ENV: ${{ inputs.target-env }}
      DEPLOYMENT_MODE: ${{ inputs.deployment-mode }}
      CHECK_ONLY: ${{ inputs.check-only }}
      OUTPUT_DIR: ${{ inputs.outputdir }}
      CHANGE_DETECTION_TYPE: ${{ inputs.change-detection-type }}
      TEST_CLASS_REGEX: ${{ inputs.test-class-regex }}

    steps:
    
      - name: â¬‡ï¸ Checkout Repository (Salesforce Project)
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          
      - name: âš™ï¸ Initialize Pipeline
        run: |
          # Set COMPARE_WITH based on check-only
          COMPARE_WITH="${{ inputs.check-only == true && vars.VAL_COMPARE_WITH || vars.DEP_COMPARE_WITH }}"
          
          # Set DELTA_MODE based on check-only (using the ternary operator)
          DELTA_MODE="${{ inputs.check-only == true && vars.VAL_DELTA_MODE || vars.DEP_DELTA_MODE }}"
          
          # Set TEST_LEVEL using the nested condition
          TEST_LEVEL="${{ inputs.test-level != '' && inputs.test-level || (inputs.check-only == true && vars.VAL_TEST_LEVEL || vars.DEP_TEST_LEVEL) }}"
          
          # Export these variables so they are available to subsequent commands
          # (Optional, but good practice if you have more commands in this script)
          echo "COMPARE_WITH=$COMPARE_WITH" >> $GITHUB_ENV
          echo "DELTA_MODE=$DELTA_MODE" >> $GITHUB_ENV
          echo "TEST_LEVEL=$TEST_LEVEL" >> $GITHUB_ENV

          # -----------------------------------------------------------------
          # START: CREATE CONFIGURATION SUMMARY
          # -----------------------------------------------------------------
          
          echo "## âš™ï¸ CI/CD Configuration Summary" >> $GITHUB_STEP_SUMMARY
          echo "---" >> $GITHUB_STEP_SUMMARY
          echo "| Setting | Value |" >> $GITHUB_STEP_SUMMARY
          echo "| :--- | :--- |" >> $GITHUB_STEP_SUMMARY
          
          # Workflow Inputs
          echo "| **Target Environment** | ${{ inputs.target-env }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Deployment Mode | ${{ inputs.deployment-mode }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Delta Mode | $DELTA_MODE |" >> $GITHUB_STEP_SUMMARY
          echo "| Compare With | \`$COMPARE_WITH\` |" >> $GITHUB_STEP_SUMMARY
          echo "| **Check Only (Validation)** | ${{ inputs.check-only }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Test Level | $TEST_LEVEL |" >> $GITHUB_STEP_SUMMARY
          echo "| Run Code Scanner | ${{ inputs.run-code-scanner }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Run Org Pre-Config | ${{ inputs.org-preconfig }} |" >> $GITHUB_STEP_SUMMARY

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Configuration established successfully. Starting pipeline execution..." >> $GITHUB_STEP_SUMMARY
          
          # -----------------------------------------------------------------
          # END: CREATE CONFIGURATION SUMMARY
          # -----------------------------------------------------------------
          
          npm install --save-dev
          sf plugins link $(npm root -g)/dxb
          sf plugins
          git config --global --add safe.directory $PWD
        shell: bash
          
      # 1. Login to Salesforce (using the common, fixed secret AUTH_URL)
      - name: ðŸ”‘ Salesforce Login
        env:
            SF_AUTH_URL: ${{ secrets.AUTH_URL }}
        run: |
          if [ -z "$SF_AUTH_URL" ]; then
              # Use single quotes inside the double-quoted string, or escape them
              echo "::error::SFDX Auth URL secret not found. Ensure the calling workflow passes the secret via the 'AUTH_URL' key in your environment settings."
              exit 1
          fi
          
          echo "$SF_AUTH_URL" > credentials.txt
          # Use the environment variable $TARGET_ENV
          sf org login sfdx-url -f credentials.txt -a "$TARGET_ENV" -s
        shell: bash
      # 2. Run Delta
      - name: ðŸ§® Calculate Delta
        id: calculate_delta
        run: |
          # Use environment variables which are easier to read and less error-prone
          if [ "$DEPLOYMENT_MODE" = "FULL" ]
          then
            echo "--- Full Deployment Mode ---"
            allPackageDirectories=""
            json=$(cat sfdx-project.json)
            for i in $(echo "$json" | jq -r '.packageDirectories[].path'); do
              allPackageDirectories+=" --source-dir $i"
            done
            echo "sf project generate manifest $allPackageDirectories -d $OUTPUT_DIR"
            sf project generate manifest $allPackageDirectories -d $OUTPUT_DIR
            
            # Setup for full deployment tests
            echo "./**/*.cls" > apexclasses
            echo "" > testClasses
            echo "::set-output name=noChanges::false" # Force deployment if FULL mode

          else # DELTA Deployment Mode
            echo "--- Delta Deployment Mode (Comparing with $COMPARE_WITH) ---"
            #increase git file name config
            #git config diff.renameLimit 999999
            
            # 1. Generate package.xml and check for changes
            echo "sf dxb source delta -m $DELTA_MODE -k $COMPARE_WITH -p $OUTPUT_DIR -g"
            sf dxb source delta -m $DELTA_MODE -k $COMPARE_WITH -p $OUTPUT_DIR -g
            
            # Check if package.xml contains actual metadata members
            if ! grep -q '<members>' "$OUTPUT_DIR/package.xml"; then
              echo "No changes detected. Skipping deployment."
              echo "noChanges=true" >> $GITHUB_OUTPUT
              exit 0
            fi

            # 2. Extract Apex classes and test classes for specified tests
            sf dxb source delta -k $COMPARE_WITH --json | jq -c '.result.deltaMeta[] | select (endswith(".cls"))' | paste -sd, - | sed 's/"//g' > apexclasses
            cat $OUTPUT_DIR/package.xml
            
            if [ "$TEST_LEVEL" = "RunSpecifiedTests" ]; then 
              echo "sf dxb source fetchtest -x $OUTPUT_DIR/package.xml -t $CHANGE_DETECTION_TYPE --test-class-name-regex $TEST_CLASS_REGEX -d . > testClasses"
              sf dxb source fetchtest -x $OUTPUT_DIR/package.xml -t $CHANGE_DETECTION_TYPE --test-class-name-regex $TEST_CLASS_REGEX -d . > testClasses    
              cat testClasses
            fi
            echo "noChanges=false" >> $GITHUB_OUTPUT

          fi
        shell: bash
        
        # 3. âš™ï¸ Set Specific Org Data (New Conditional Step)
      - name: âš™ï¸ Set Specific Org Data
        if: ${{ inputs.org-preconfig == true }}
        run: |
          TARGETENV= ${{ inputs.target-env }}
          # Check if the output of 'sfdx-env-mapping' is non-empty
          if [[ -s "${{ vars.ORG_SPEC_METADATA_DEF }}" ]]; then
            CONFIG_FILE="${{ vars.ORG_SPEC_METADATA_DEF }}"
            echo "Running: sf dxb org data --config $CONFIG_FILE --environment $TARGETENV"
            sf dxb org data --config "$CONFIG_FILE" --environment "$TARGETENV"
          else
            echo "Org. Spec Metadata Def file is empty or not found. Skipping 'Set Specific Org Data'. Go to Settings > Environment and add variable 'ORG_SPEC_METADATA_DEF' with the path of your file."
          fi
        shell: bash
        
      - name: ðŸ›¡ï¸ Run Code Analyzer
        id: code_analyzer
        continue-on-error: true # Azure's 'continueOnError: true'
        if: ${{ inputs.run-code-scanner == true }}
        run: |
          # apexclasses file was generated in the 'Calculate Delta' step.
          # It contains a comma-separated list of changed Apex class paths.
          APEX_CLASSES=$(cat apexclasses)
          
          # Check if the file content is NOT empty/just whitespace, similar to Azure's 'if [[ ! -z "$apexclasses" ]]'
          if [[ -s apexclasses ]]; then
            echo "--- Starting Code Scan on $APEX_CLASSES ---"
            
            # Create output directory
            mkdir -p codeanalyzeroutput
            
            # Run the scan. We use the SEVERITY_THRESHOLD env var defined earlier.
            sf code-analyzer run \
              -t "$APEX_CLASSES" \
              -f "codeanalyzeroutput/code-scanner-results.csv" \
            
            # Set output variable to track if a report was generated (equivalent to Azure's task.setvariable)
            echo "codeScannerReportExists=true" >> $GITHUB_OUTPUT
          
          else
            echo "Nothing to scan (apexclasses file is empty)."
            echo "codeScannerReportExists=false" >> $GITHUB_OUTPUT
          fi
        shell: bash

      - name: ðŸš€ Salesforce Deployment
        # Use an 'if' condition to ensure this step only runs if noChanges is false.
        # We assume you set a step output or environment variable 'noChanges'
        # in your 'Calculate Delta' step.
        id: sfdeploy
        if: ${{ steps.calculate_delta.outputs.noChanges == 'false' }}
        run: |
          echo "runTests=false" >> $GITHUB_OUTPUT
          OPTIONS=" -g --wait 666 --json"
          predestructivepath="${{ vars.PRE_DESTRUCTIVE_XML_PATH }}"
          postdestructivepath="${{ vars.POST_DESTRUCTIVE_XML_PATH }}"
          
          # --- TEST CLASSES (Requires output from 'Calculate Delta' step if RunSpecifiedTests is used) ---
          # Since you didn't define testClasses globally, we assume it's calculated in the delta step.
          # For simplicity, we'll try to use the logic from your provided code:
          TESTCLASSES=""
          if [ "$TEST_LEVEL" = "RunSpecifiedTests" ]; then 
            # Assuming 'testClasses' file was created by 'Calculate Delta'
            if [ -f "testClasses" ]; then
              input_string=$(cat testClasses)
              IFS=',' read -ra values <<< "$input_string"
              for value in "${values[@]}"; do
                TESTCLASSES+="-t $value "
              done
            fi

            if [ -z "$TESTCLASSES" ]; then
                echo "âš ï¸ No test classes found. Downgrading TEST_LEVEL to NoTestRun."
                TEST_LEVEL="NoTestRun"
            fi
          fi
          
          # -----------------------------------------------------------
          # 2. Re-apply Deployment Option Overrides
          # -----------------------------------------------------------
          
          if [ "$CHECKONLY" = "true" ]; then
              OPTIONS="$OPTIONS --dry-run"
          fi
          if [ -n "$predestructivepath" ] && [ -f "$predestructivepath" ]; then
              OPTIONS="$OPTIONS --pre-destructive-changes $predestructivepath"
          fi
          if [ -n "$postdestructivepath" ] && [ -f "$postdestructivepath" ]; then
              OPTIONS="$OPTIONS --post-destructive-changes $postdestructivepath"
          fi
          if [ "$TEST_LEVEL" = "RunSpecifiedTests" ] || [ "$TEST_LEVEL" = "RunLocalTests" ] ; then
              OPTIONS="$OPTIONS --junit --results-dir testresults/apex --coverage-formatters cobertura"
              echo "runTests=true" >> $GITHUB_OUTPUT
          fi
          
          echo "--- Initiating Deployment ---"
          echo "Test Level: $TEST_LEVEL"
          echo "Test Classes: $TESTCLASSES"
          echo "Deployment Options: $OPTIONS"
          
          # -----------------------------------------------------------
          # 3. Execute the SFDX Deployment Command
          # -----------------------------------------------------------
          echo "sf project start deploy -o ${{ inputs.target-env }} -x ${{ inputs.outputdir }}/package.xml -l $TEST_LEVEL $TESTCLASSES $OPTIONS" 
          # Use the target-env input, the package.xml from the delta step,
          # and all the calculated variables.
          
          # The command execution
          sf project start deploy \
            -o ${{ inputs.target-env }} \
            -x ${{ inputs.outputdir }}/package.xml \
            -l $TEST_LEVEL \
            $TESTCLASSES \
            $OPTIONS > deployResult.json
            
          # Output the result
          cat deployResult.json | jq 
      
        shell: bash
        
      - name: ðŸ§¹ Coverage Cleanup and Checks
        # Only run if tests were executed successfully (based on the previous step's output)
        if: ${{ always() && steps.sfdeploy.outputs.runTests == 'true' }}
        id: codecoveragecheck
        run: |
          # Define file paths
          COVERAGE_FILE="testresults/apex/coverage/cobertura.xml"
          JUNIT_FILE="testresults/apex/junit/junit.xml"
          
          # Map optional inputs (assuming they exist in your workflow_call inputs)
          MINCODECOVERAGE="${{ vars.MIN_CODE_COVERAGE }}"
          CHECKPERFORMANCE="${{ vars.CHECKPERFORMANCE }}"
          
          # Map other required inputs
          CHECKONLY="${{ inputs.check-only }}"
          
          # Check if both report files exist before proceeding
          if [ -e "$COVERAGE_FILE" ] && [ -e "$JUNIT_FILE" ]; then
              
              echo "--- Starting Apex Report Cleanup ---"
              echo "sf dxb apex coverage cleanup -f $COVERAGE_FILE"
              echo "Update code coverage cobertura file to align apex class file path..."
              
              # Displaying the content BEFORE cleanup (for debugging/logs)
              # We limit the output to prevent log spam if the file is huge
              echo "--- Cobertura XML before cleanup (first 20 lines) ---"
              head -n 20 "$COVERAGE_FILE"
              echo "--------------------------------------------------------"
              
              # 1. Clean up the Cobertura XML file paths
              sf dxb apex coverage cleanup -f "$COVERAGE_FILE"
              
              # -------------------------------------------------------------
              # 2. Check Minimum Code Coverage
              # -------------------------------------------------------------
              
              # The coverage check should only be run if mincodecoverage is provided AND it's a validation run (Check Only)
              if [ -n "$MINCODECOVERAGE" ] && [ "$CHECKONLY" = "true" ]; then
                  echo "--- Verify Minimum Apex Code Coverage: $MINCODECOVERAGE% ---"
                  echo "sf dxb apex coverage check -f $COVERAGE_FILE -c $MINCODECOVERAGE"
                  
                  # This command will fail the step if coverage is too low
                  sf dxb apex coverage check -f "$COVERAGE_FILE" -c "$MINCODECOVERAGE"
              fi
              
              # -------------------------------------------------------------
              # 3. Check Performance (JUNIT)
              # -------------------------------------------------------------
              # The performance check runs if the input is provided
              if [ -n "$CHECKPERFORMANCE" ]; then
                  # Assuming CHECKPERFORMANCE provides the max time (e.g., "3" for 3 seconds)
                  MAX_TIME_SECONDS="$CHECKPERFORMANCE"
                  echo "--- Verify Test Performance (Max $MAX_TIME_SECONDS seconds) ---"
                  echo "sf dxb junit check -p $JUNIT_FILE -t $MAX_TIME_SECONDS"
                  
                  # This command will fail the step if any test takes longer than the threshold
                  sf dxb junit check -p "$JUNIT_FILE" -t "$MAX_TIME_SECONDS"
              fi
              
          else
              echo "Skipping coverage cleanup/checks: Required files ($COVERAGE_FILE or $JUNIT_FILE) not found."
          fi
        shell: bash

      - name: ðŸŽ¨Cobertura Summary
        # Ensure this step runs only if tests ran and produced the XML
        if: ${{ always() && steps.sfdeploy.outputs.runTests == 'true' }}
        run: |
          # Define file paths and GitHub URLs
          COVERAGE_FILE="testresults/apex/coverage/cobertura.xml"
          BASE_FILE_URL="${{ vars.GH_BASE_URL }}${{ github.ref_name }}/"
      
          # -------------------------------------------------------------
          # 1. WRITE HEADER
          # -------------------------------------------------------------
          
          # Extract global coverage data for the header (as before)
          SUMMARY_DATA=$(grep -oP '<coverage [^>]*>' "$COVERAGE_FILE" | head -1)
          LINE_RATE=$(echo "$SUMMARY_DATA" | grep -oP 'line-rate="\K[^"]+')
          COVERAGE_PCT=$(awk "BEGIN {printf \"%.2f\n\", $LINE_RATE * 100}")
          
          # Write header
          echo "## ðŸŽ¯ File-Level Code Coverage Summary (${COVERAGE_PCT}%)" >> $GITHUB_STEP_SUMMARY
          echo "---" >> $GITHUB_STEP_SUMMARY
          
          # Define the new table structure
          echo "| File | Line Coverage | ðŸ”´ Uncovered Lines |" >> $GITHUB_STEP_SUMMARY
          echo "| :--- | :---: | :--- |" >> $GITHUB_STEP_SUMMARY
          
          # -------------------------------------------------------------
          # 2. EXTRACT AND FORMAT FILE-LEVEL DETAIL (The complex part)
          # -------------------------------------------------------------
          
          # AWK script to process the XML:
          # 1. Finds the filename and line-rate from the <class> tag.
          # 2. Iterates through subsequent <line> tags to find 'hits="0"'.
          # 3. Prints one formatted Markdown row per file.
          
          awk -v BASE_URL="$BASE_FILE_URL" '
          # Initialize variables for each file block
          BEGIN { LINES_MISSED=""; FILENAME=""; CLASS_RATE=""; }
      
          # Pattern match for the end of a class block, and print the results
          /<class name=/ { 
              # Before processing the new class, check if the previous one had any missed lines
              if (FILENAME != "" && LINES_MISSED != "") {
                  # Format the output table row (only if missed lines exist)
                  printf "| [%s](%s) | **%s%%** | %s |\n", CLASS_NAME, FILE_HYPERLINK, CLASS_RATE_PCT, LINES_MISSED | "cat >> $GITHUB_STEP_SUMMARY"
              }
              
              # Reset variables for the new class
              LINES_MISSED="";
              
              # Extract filename (full relative path)
              match($0, /filename="[^"]+"/)
              FULL_PATH=substr($0, RSTART+10, RLENGTH-11)
              
              # Extract class name (for display)
              match($0, /name="[^"]+"/)
              CLASS_NAME=substr($0, RSTART+6, RLENGTH-7)
              
              # Extract class line-rate (for percentage column)
              match($0, /line-rate="[^"]+"/)
              CLASS_RATE=substr($0, RSTART+11, RLENGTH-12)
              
              # Calculate percentage and file link
              CLASS_RATE_PCT = sprintf("%.0f", CLASS_RATE * 100);
              FILE_HYPERLINK = BASE_URL FULL_PATH;
      
              # Store the current filename and rate for the next print cycle
              FILENAME=FULL_PATH;
          }
      
          # Pattern match for uncovered lines (hits="0")
          /<line / && /hits="0"/ {
              # Extract line number
              match($0, /number="[^"]+"/)
              LINENUM=substr($0, RSTART+8, RLENGTH-9)
              
              # Append line number to the list
              if (LINES_MISSED == "") {
                  LINES_MISSED = LINENUM;
              } else {
                  LINES_MISSED = LINES_MISSED ", " LINENUM;
              }
          }
      
          # End of file: process the very last class block
          END {
              if (FILENAME != "" && LINES_MISSED != "") {
                   printf "| [%s](%s) | **%s%%** | %s |\n", CLASS_NAME, FILE_HYPERLINK, CLASS_RATE_PCT, LINES_MISSED | "cat >> $GITHUB_STEP_SUMMARY"
              }
          }' "$COVERAGE_FILE"
      
          echo "---" >> $GITHUB_STEP_SUMMARY
          echo "*Files with 100% coverage are not listed in the detail section.*" >> $GITHUB_STEP_SUMMARY
          echo "[Download Full Cobertura XML Report Artifact]" >> $GITHUB_STEP_SUMMARY
        shell: bash

        # 8. Data Import (New Conditional Step)
      - name: ðŸ“¥ Run Data Import
        # CRITICAL IF: Only run if it was a successful *deployment* (not validation)
        if: ${{ inputs.run-data-import == true &&inputs.check-only == false && success() }}
        
        run: |
          # The variable is a repository/environment variable, accessed via the `vars` context
          DATA_DEF_FILE="${{ vars.DATA_DEF_FILE }}"
          
          if [ -z "$DATA_DEF_FILE" ]; then
            echo "::warning::vars.DATA_DEF_FILE is empty. Skipping data import."
            exit 0
          fi
          
          echo "--- Starting Data Import ---"
          echo "Using data definition file: $DATA_DEF_FILE"
          
          # Execute the sf dxb data import command
          # Note: The target org (-o) is already the default due to the 'sf org login' step
          sf dxb data import -f "$DATA_DEF_FILE" -d data
          
          echo "Data Import complete."

        shell: bash

        # Community Publish (New Step - Simplified access)
      - name: ðŸŒ Publish Experience Cloud Community
        # Only run if CHECK_ONLY is 'false' (it's a real deployment)
        if: ${{ inputs.check-only ==  false && inputs.auto-publish-communities ==  true }}
        
        run: |
          echo "Publishing Experience Cloud site for target: ${{ env.TARGET_ENV }}"
          sf dxb community publish

        shell: bash

      - name: ðŸ“Š Generate Deployment Report
        if: ${{ always() && steps.sfdeploy.outputs.runTests == 'true' }}
        run: |
          # Create reports directory if it doesn't exist
          mkdir -p reports
          
          # Generate deployment report in markdown format
          # Paths adapted for Linux (Ubuntu runner)
          sf dxb deployment report \
            -a codeanalyzeroutput/code-scanner-results.html \
            -c \
            -d reports \
            -f deployResult.json \
            -j testresults/apex/junit/junit.xml \
            -b testresults/apex/coverage/cobertura.xml \
            -r markdown \
            -t "Salesforce Deployment Report"
          
          # Append the generated report to GitHub Step Summary if it exists
          if [ -f "reports/deployment-report.md" ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            cat reports/deployment-report.md >> $GITHUB_STEP_SUMMARY
          fi
        shell: bash

      - name: ðŸ§ª Run LWC JEST Tests
        if: ${{ inputs.runjest ==  true }}
        uses: davidbrowaeys/SafireForGitHub/.github/actions/sfdx-lwc-test-run@main
        with:
          runDeltaTest: ${{ inputs.deployment-mode == 'DELTA' }}
          deltaManifest: ${{ inputs.outputdir }}/package.xml
          failTaskOnFailedTests: ${{ inputs.check-only }}
          checkPerformance: false
          
      - name: ðŸ“¤ Publish Code Analyzer Report
        uses: actions/upload-artifact@v4
        
        if: ${{ steps.code_analyzer.outputs.codeScannerReportExists == 'true' }}
        with:
          name: Code-Analyzer-Report-${{ inputs.target-env }}
          path: codeanalyzeroutput/code-scanner-results.html
          
          retention-days: 7
